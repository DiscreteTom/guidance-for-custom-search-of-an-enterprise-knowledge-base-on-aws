{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e116b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.25.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: numexpr in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.8.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from numexpr) (1.25.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: unstructured in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.10.4)\n",
      "Requirement already satisfied: chardet in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: filetype in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (4.9.3)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (2.29.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: emoji in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from unstructured) (2.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.3.2.post1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk->unstructured) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk->unstructured) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk->unstructured) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk->unstructured) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->unstructured) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->unstructured) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->unstructured) (2023.5.7)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: python-pptx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.6.21)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-pptx) (4.9.3)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-pptx) (9.5.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-pptx) (3.1.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tiktoken) (2023.8.8)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tiktoken) (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy\n",
    "!pip install --upgrade numexpr\n",
    "!pip install unstructured\n",
    "!pip install python-pptx\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94688a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import traceback\n",
    "import urllib.parse\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import time\n",
    "from smart_search import SmartSearchQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6932c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host: search-smartsearch-soghr3slgoubn2356ox22gitoy.us-west-1.es.amazonaws.com\n",
      "region: us-west-1\n"
     ]
    }
   ],
   "source": [
    "#根据时间情况修改index和language值\n",
    "# EMBEDDING_ENDPOINT_NAME = \"huggingface-inference-eb\"\n",
    "\n",
    "# index =  \"smart_search_qa_test_0826_cn\"\n",
    "# language = \"chinese\"\n",
    "# EMBEDDING_ENDPOINT_NAME = \"huggingface-inference-eb-bge-zh\"\n",
    "\n",
    "index =  \"smart_search_qa_test_0826_en_3\"\n",
    "language = \"english\"\n",
    "EMBEDDING_ENDPOINT_NAME = \"huggingface-inference-eb-bge-en\"\n",
    "\n",
    "port = 443\n",
    "bulk_size = 10000000\n",
    "\n",
    "\n",
    "sm_client = boto3.client('secretsmanager')\n",
    "master_user = sm_client.get_secret_value(SecretId='opensearch-host-url')['SecretString']\n",
    "data= json.loads(master_user)\n",
    "es_host_name = data.get('host')\n",
    "host = es_host_name+'/' if es_host_name[-1] != '/' else es_host_name# cluster endpoint, for example: my-test-domain.us-east-1.es.amazonaws.com/\n",
    "host = host[8:-1]\n",
    "region = boto3.Session().region_name # e.g. cn-north-1\n",
    "print('host:',host)\n",
    "print('region:',region)\n",
    "\n",
    "# retrieve secret manager value by key using boto3                                             \n",
    "sm_client = boto3.client('secretsmanager')\n",
    "master_user = sm_client.get_secret_value(SecretId='opensearch-master-user')['SecretString']\n",
    "data= json.loads(master_user)\n",
    "username = data.get('username')\n",
    "password = data.get('password')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c1833d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to load ../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf file\n",
      "begin ini spliter,chunk_size: 500\n",
      "finish ini spliter\n",
      "data: [Document(page_content=' 1  AWS Service Approval Accelerator AWS Lake Formation (ALF)   March 24th, 2021            Table of Contents Summary ................................................................................................................................ 2 AWS Lake Formation: Introduction ......................................................................................... 2 AWS Lake Formation: Benefits ................................................................................................ 3 How Lake Formation works .................................................................................................... 4 Security and Access Control to Metadata and Data in Lake Formation .................................... 5 Lake Formation Personas and IAM Permissions ...................................................................... 8 Cross-Account Access .............................................................................................................. 9 AWS Lake Formation Controls and Architecture .................................................................... 10          ', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 0}), Document(page_content=' 1 Summary   This document provides an overview of AWS Lake Formation (ALF) along with a compiled list of security controls and best practices for ALF to assist security teams in assessing ALF’s fitness for use.   AWS Lake Formation: Introduction  A data lake is a centralized, curated, and secured repository that stores all your data, both in its original form and prepared for analysis. It enables you to break down data silos and combine different types of analytics to gain insights and guide better business decisions.  However, setting up and managing data lakes today involves a lot of manual, complicated, and time-consuming tasks: • Loading data from diverse sources • Monitoring the data flows • Setting up partitions • Turning on encryption and managing keys • Defining transformation jobs and monitoring their operation • Re-organizing data into a columnar format • Configuring access control settings • Deduplicating redundant data, matching linked records • Granting access to data sets, and auditing access over time.  AWS Lake Formation is a fully managed service that makes it easier for you to build, secure, and manage data lakes. Lake Formation builds on the capabilities available in AWS Glue.  Lake Formation simplifies and automates many of the complex manual steps such as  collecting, cleansing, moving, and cataloging data, and securely making that data available for analytics and machine learning.            ', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 1}), Document(page_content=' 1 AWS Lake Formation: Benefits   Build data lakes quickly • With Lake Formation, you can move, store, catalog, and clean your data faster.  You simply point Lake Formation at your data sources, and Lake Formation crawls those sources and moves the data into your new Amazon S3 data lake.  • Lake Formation organizes data in S3 around frequently used query terms and into right-sized chunks to increase efficiency.  • Lake Formation changes data into formats like Apache Parquet and ORC for faster analytics.  • Lake Formation has built-in machine learning to deduplicate and find matching records (two entries that refer to the same thing) to increase data quality.  Simplify security management • Lake Formation provides its own permissions model that augments the AWS Identity and Access Management (IAM) permissions and enables fine-grained access to data stored in data lakes through a simple grant/revoke mechanism.  • Lake Formation permissions are enforced at the table and column level across the full portfolio of AWS analytics and machine learning services. • Lake Formation is used to centrally define security, governance, and auditing policies in one place, versus doing these tasks per service.  • Your policies are consistently implemented, eliminating the need to manually configure them across services like AWS IAM, AWS KMS, Amazon S3, Redshift, Athena, and (in beta) EMR for Apache Spark.   Provide self-service access to data • By providing a catalog of your data with consistent security enforcement, Lake Formation makes it easier for your analysts and data scientists to use their preferred analytics service. • Your users can use diverse data sets now housed in a single data lake. They can also combine these services without having to move data between silos.             ', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 2}), Document(page_content=' 1 How Lake Formation works  The following diagram illustrates how data is loaded and secured in Lake Formation.  \\n  AWS Lake Formation makes it easier for you to build, secure, and manage data lakes. Lake Formation helps you do the following, either directly or through other AWS services: 1. Register the Amazon Simple Storage Service (Amazon S3) buckets and paths where your data lake will reside. 2. Orchestrate data flows that ingest, cleanse, transform, and organize raw data. 3. Create and manage a Data Catalog containing metadata about data sources and data in the data lake. 4. Define granular data access policies to the resources • metadata  • underlying data   As the diagram shows, Lake Formation manages AWS Glue crawlers, AWS Glue ETL jobs, the Data Catalog, security settings, and access control. After the data is securely stored in the data lake, users can access the data through their choice of analytics services, including Amazon Athena, Amazon Redshift, and Amazon EMR.  AWS Lake Formation is built on AWS Glue and interacts in the following ways: • Lake Formation and AWS Glue share the same Data Catalog. • AWS Glue To orchestrate jobs and crawlers to transform data • The workflows generated with LF blueprint are AWS Glue workflows.  • ML transforms are provided with LF and are built on AWS Glue API operations.    \\n', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 3}), Document(page_content=' 1 Security and Access Control to Metadata and Data in Lake Formation  Lake Formation uses a combination of Lake Formation and IAM permissions. 1. Lake Formation permissions control access to Data Catalog resources: • Metadata (AWS Data Catalog) • Underlying data at S3 locations 2. IAM permissions control access to the ALF and AWS Glue APIs and resources.   \\n  AWS Lake Formation Fine-grained Access   IAM Permissions Lake Formation Permissions Coarse-grained:  Broader permissions on individual operations and on access to Amazon S3 locations.  For example, include \"glue:*\" or \"glue:Create*\" rather than \"glue:CreateTables\", leaving Lake Formation permissions to control whether or not a principal can create catalog objects. Fine-grained:  Granting limited Lake Formation permissions to individual principals on individual Data Catalog resources, Amazon S3 locations, and the underlying data in those locations.        \\n', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 4}), Document(page_content=' 1 Access control in AWS Lake Formation is divided into the following two areas:  1. Metadata access control (Data Catalog permissions) • To create, read, update, and delete metadata databases, tables in Data Catalog.  2. Underlying data access control • Data access permissions to read and write data to underlying Amazon S3 locations.  • Data location permissions to create metadata databases and tables that point to specific Amazon S3 locations.   Access control in AWS Lake Formation  Data Catalog permissions Data access permissions Data location permissions Catalog Database Table Table S3 Location CREATE_DATABASE CREATE_TABLE ALTER DROP DESCRIBE ALTER DROP DESCRIBE  SELECT INSERT DELETE DATA_LOCATION_ACCESS                         ', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 5}), Document(page_content=' 1 Metadata access control   Metadata access control   Lake Formation Permissions Resource  Required additional IAM permission  Granted Access CREATE_DATABASE  Need data location permissions if the  location property is specified, and the location is managed by Lake Formation. Data Catalog glue:CreateDatabase Create a metadata database or resource link in the Data Catalog.   CREATE_TABLE in the database, ALTER database, DROP database. CREATE_TABLE  All Lake Formation permissions on the table are granted to the principal who creates a table. Database glue:CreateTable Create a metadata table or resource link in the Data Catalog within the specified database. ALTER  Need data location permissions if the property being altered is a registered Amazon S3 location. Database glue:UpdateDatabase Alter metadata of  a database. Table glue:UpdateTable Alter metadata of  a table. DROP  Cannot be granted  on a database to an external account or organization.  Dropping a database drops all tables in the database. Database glue:DeleteDatabase Drop a database in Data Catalog. Table glue:DeleteTable Drop a table in Data Catalog. Resource link glue:DeleteDatabase glue:DeleteTable Drop a resource link  in Data Catalog. DESCRIBE  Implicitly granted if a user has other Lake Formation permissions on a database, table, or resource link. Database glue:GetDatabase  View metadata of a database. Table glue:GetTable  View metadata of a table. Resource link glue:GetTable   glue:GetDatabase  View metadata of a resource link    ', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 6}), Document(page_content=\" 1 Underlying data access control  To enable Lake Formation principals to read and write underlying data with access controlled by Lake Formation permissions:  1. The Amazon S3 locations that contain the data must be registered with Lake Formation.  2. Principals who create Data Catalog tables that point to underlying data locations must have data location permissions.  3. Principals who read and write underlying data must have Lake Formation data access permissions on the Data Catalog tables that point to the underlying data locations. They must also have lakeformation:GetDataAccess IAM permission. • Amazon Athena requires the user to have this permission.  • Assumed role for other integrated services must have this permission.   When an integrated AWS service requests access to data in an Amazon S3 location that is access-controlled by AWS Lake Formation, Lake Formation supplies temporary credentials to access the data.   Underlying data access control  Lake Formation Permissions Resource  Required additional IAM permission  Granted Access INSERT   TABLE lakeformation: GetDataAccess Insert, update, and read underlying data at the Amazon S3 location specified by the table. SELECT  When granting SELECT, you can't include the grant option if column filtering is applied.   You cannot restrict access control on columns that are partition keys. TABLE lakeformation: GetDataAccess Read the underlying data in Amazon S3 at the location specified by the table.  If column filtering was applied when this permission was granted, the principal can view the metadata only for the included columns and can query data only from the included columns DELETE   TABLE lakeformation: GetDataAccess Delete underlying data at the Amazon S3 location specified by the table.   \", metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 7}), Document(page_content=' 1 Data Location Permissions Data location permissions in AWS Lake Formation enable principals to create and alter Data Catalog metadata that point to designated registered Amazon S3 locations.   Data location permissions provide an extra layer of security to locations within the data lake. When you grant the CREATE_TABLE or ALTER permission to a principal, you also grant data location permissions to limit the locations for which the principal can create or alter metadata tables.  Data location permissions govern the outcome of create and update operations on Data Catalog databases and tables. The rules are as follows:  • A principal must have explicit or implicit data location permissions on an Amazon S3 location to create or update a database or table that specifies that location.  • The explicit permission DATA_LOCATION_ACCESS can be granted using the console, API, or AWS CLI.  • If a principal is granted data location permissions on a location, the principal has data location permissions on all child locations.  • Data location permissions apply only to creating or altering Data Catalog databases and tables that point to the location.  • A principal does not need data location permissions to perform read/write operations on the underlying data on existing tables.. It is sufficient to have the SELECT or INSERT data access permissions.                        ', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 8}), Document(page_content=\" 1 Cross-Account Access  Large enterprises typically use multiple AWS accounts, and many of those accounts might need access to a data lake managed by a single AWS account.   AWS Lake Formation allows cross-account access to Data Catalog metadata and underlying data. Users and AWS Glue ETL jobs can query and join tables across multiple accounts and still take advantage of Lake Formation table-level and column-level data protections.  You don't share resources with specific principals in external AWS accounts—you share the resources only with the accounts. Granting Lake Formation permissions to an organization or organizational unit is equivalent to granting the permission to every AWS account in that organization or organizational unit.   AWS Resource Access Manager  When you grant Lake Formation permissions on a Data Catalog resource to an external account, Lake Formation uses the AWS Resource Access Manager (AWS RAM) service to share the resource.   • If the grantee account is in the same organization as the grantor account, the shared resource is available immediately to the grantee.   • If the grantee account is not in the same organization, AWS RAM sends an invitation to the grantee account to accept or reject the resource grant. Then, to make the shared resource available, the data lake administrator in the grantee account must use the AWS RAM console or CLI to accept the invitation.                           \", metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 9}), Document(page_content=' 1 Lake Formation Personas and IAM Permissions  The following tables lists the suggested AWS Lake Formation personas and their permissions.  AWS Lake Formation Personas Persona  Description IAM administrator (superuser) (Required) User who can create IAM users and roles. Has the AdministratorAccess AWS managed policy. Has all permissions on all Lake Formation resources. Can add data lake administrators. Cannot grant Lake Formation permissions if not also designated a data lake administrator. Data lake administrator (Required) User who can register Amazon S3 locations, access the Data Catalog, create databases, create and run workflows, grant Lake Formation permissions to other users, and view AWS CloudTrail logs. Has fewer IAM permissions than the IAM administrator, but enough to administer the data lake. Cannot add other data lake administrators. Workflow role (Required) Role that runs a workflow on behalf of a user. You specify this role when you create a workflow from a blueprint. Data engineer User who can create and run crawlers and workflows and grant Lake Formation permissions on the Data Catalog tables that the crawlers and workflows create. Data analyst User who can run queries against the data lake using, for example, Amazon Athena. Has only enough permissions to run queries.   AWS Managed Policy Comments AWSGlueConsoleFullAccess Allows the principal to conduct a variety of operations on the Lake Formation console. AWSLakeFormationDataAdmin Allows the data lake administrator to conduct administrative operations and view AWS CloudTrail logs. AWSLakeFormationCrossAccountManager Allows the principal to grant Lake Formation permissions to external AWS accounts, to organizations, or to organizational units.  The AWSLakeFormationDataAdmin policy does not grant every required permission for data lake administrators. Additional permissions are needed to create and run workflows and register locations with the service linked role AWSServiceRoleForLakeFormationDataAccess. For more information, see Create a Data Lake Administrator and Using Service-Linked Roles for Lake Formation.  In addition, AWS Glue and Lake Formation assume the service role AWSGlueServiceRole to allow access to related services, including Amazon Elastic Compute Cloud (Amazon EC2), Amazon Simple Storage Service (Amazon S3), and Amazon CloudWatch. ', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 10}), Document(page_content=' 1 AWS Lake Formation Controls and Architecture   The following topics answers common security concerns to the corresponding controls and architectural best practices as documented in AWS public documentation, white papers, and blog posts.   AWS Lake Formation Controls and Architecture  Network Isolation  • Lake Formation supports private endpoints in your VPC and records all activity in AWS CloudTrail, so you have network isolation and auditability. • AWS Lake Formation provides API operations through several language-specific SDKs and the AWS Command Line Interface (AWS CLI).  • The Lake Formation API focuses primarily on managing Lake Formation permissions, while the AWS Glue API provides a data catalog API and a managed infrastructure for defining, scheduling, and running ETL operations on your data. • If your organization uses transit gateway to scale your network or private link , ALF/ AWS Glue does support through VPC Isolation of physical hosts, update/patch/ harden the hosts AWS Lake Formation is serverless managed service. There is no infrastructure to provision or manage.   Integration with IAM  • Lake Formation integrates with IAM so authenticated users and roles can be automatically mapped to data protection policies that are stored in the Data Catalog.  • The IAM integration also enables you to use Microsoft Active Directory or LDAP to federate into IAM using SAML. Compliance programs  AWS Glue and AWS Lake Formation are compliant with SOC 1, SOC 2, SOC 3, PCI, ISMAP and HIPAA.   Reference: https://aws.amazon.com/compliance/services-in-scope/ Encryption of data at-rest  • ALF currently supports Server-Side-Encryption on S3 (SSE-S3, AES-256) for encrypting your AWS Glue Data Catalog metadata and connection passwords.  • AWS KMS key is automatically used when objects, such as tables, are written to the Data Catalog.  • The encrypted objects include the Databases, Tables, Partitions, Table versions, Connections and User-defined functions.   Reference: Encrypting Your Data Catalog  Encryption in Transit  • AWS provides Secure Sockets Layer (SSL) encryption for data in motion. You can configure encryption settings for crawlers, ETL jobs, and development endpoints using security configurations in AWS ', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 11}), Document(page_content=\" 1 Glue. You can enable AWS Glue Data Catalog encryption via the settings for the Data Catalog. • As of September 4, 2018, AWS KMS (bring your own key and server-side encryption) for AWS Glue ETL and the AWS Glue Data Catalog is supported. Encryption Key Management  • AWS Lake Formation integrates with AWS KMS to enable you to more easily set up other integrated services to encrypt and decrypt data in Amazon Simple Storage Service (Amazon S3) locations.  • Both customer master keys (CMKs) and AWS managed CMKs are supported.  • Client- side encryption/decryption is not supported.  Authentication and authorization of corporate users • Beginning with Amazon EMR 5.31.0, Lake Formation supports  Federated single sign-on to EMR Notebooks or Apache Zeppelin from enterprise identity systems compatible with Security Assertion Markup Language (SAML) 2.0. • Lake Formation supports Athena users who connect through the JDBC or ODBC driver and authenticate through SAML. Supported SAML providers include Okta and Microsoft Active Directory Federation Service (AD FS). Audit Logging AWS Glue API Calls with AWS CloudTrail  AWS Glue is integrated with AWS CloudTrail to determine  • The request that was made to AWS Glue • The IP address from which the request was made • Who made the request (Root or IAM user credentials, Temporary security credentials for a role or federated user by another AWS service. When a recipient AWS account accesses data in a shared table, Lake Formation copies the CloudTrail event to the owning account's CloudTrail logs.  Reference: Logging Using CloudTrail,  Cross-Account CloudTrail Logging Alerting for Audit events  You can be notified when CloudTrail publishes new log files to your Amazon S3 bucket by using Amazon Simple Notification Service (Amazon SNS).  Reference: Configuring Amazon SNS Notifications for CloudTrail Monitoring • You can profile and monitor AWS Glue operations using AWS Glue job profiler. It collects and processes raw data from AWS Glue jobs into readable, near real-time metrics stored in Amazon CloudWatch.  • AWS Glue reports metrics to CloudWatch every 30 seconds, and the CloudWatch metrics dashboards are configured to display them every minute.  Reference: Using CloudWatch Metrics Alerts and Remediation You can use Amazon CloudWatch Events to automate your AWS services and respond automatically to system events such as application availability issues or resource changes. The actions that can be automatically triggered include:  • Activating a Lambda function when an ETL job succeeds • Notifying an Amazon SNS topic when an ETL job fails \", metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 12}), Document(page_content=' 1  Reference: Automating with CloudWatch Events Applications Development and Debugging • You can create development endpoint to iteratively develop and test ETL scripts.  • You can then create a notebook that connects to the endpoint, and use your notebook to author and test your ETL script.  \\nLake Formation Service Access  Lake Formation console: To define and manage your data lake and grant and revoke Lake Formation permissions.  Lake Formation API and CLI: The Lake Formation API focuses primarily on managing Lake Formation permissions, while the AWS Glue API provides a data catalog API and a managed infrastructure for defining, scheduling, and running ETL operations on your data.  Data Catalog: To store metadata about data lakes, data sources, transforms, and targets.  Blueprint: A data management template that enables you to easily ingest data into a data lake for a predefined source type, such as a relational database or AWS CloudTrail logs. From a blueprint, you can create a workflow.    Workflow: It consists of AWS Glue crawlers, jobs, and triggers that are generated to orchestrate the loading and update of data.    ', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 13})]\n",
      "begin load and split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 507, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs len: 56\n",
      "[Document(page_content='1  AWS Service Approval Accelerator AWS Lake Formation (ALF)   March 24th, 2021            Table of Contents Summary ................................................................................................................................ 2 AWS Lake Formation: Introduction ......................................................................................... 2 AWS Lake Formation: Benefits ................................................................................................ 3 How Lake Formation works .................................................................................................... 4 Security and Access Control to Metadata and Data in Lake Formation .................................... 5 Lake Formation Personas and IAM Permissions ...................................................................... 8 Cross-Account Access .............................................................................................................. 9 AWS Lake Formation Controls and Architecture .................................................................... 10', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 0}), Document(page_content='1 Summary   This document provides an overview of AWS Lake Formation (ALF) along with a compiled list of security controls and best practices for ALF to assist security teams in assessing ALF’s fitness for use.\\n\\nAWS Lake Formation: Introduction  A data lake is a centralized, curated, and secured repository that stores all your data, both in its original form and prepared for analysis.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 1}), Document(page_content='It enables you to break down data silos and combine different types of analytics to gain insights and guide better business decisions.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 1}), Document(page_content='However, setting up and managing data lakes today involves a lot of manual, complicated, and time-consuming tasks: • Loading data from diverse sources • Monitoring the data flows • Setting up partitions • Turning on encryption and managing keys • Defining transformation jobs and monitoring their operation • Re-organizing data into a columnar format • Configuring access control settings • Deduplicating redundant data, matching linked records • Granting access to data sets, and auditing access over time.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 1}), Document(page_content='AWS Lake Formation is a fully managed service that makes it easier for you to build, secure, and manage data lakes.\\n\\nLake Formation builds on the capabilities available in AWS Glue.\\n\\nLake Formation simplifies and automates many of the complex manual steps such as  collecting, cleansing, moving, and cataloging data, and securely making that data available for analytics and machine learning.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 1}), Document(page_content='1 AWS Lake Formation: Benefits   Build data lakes quickly • With Lake Formation, you can move, store, catalog, and clean your data faster.\\n\\nYou simply point Lake Formation at your data sources, and Lake Formation crawls those sources and moves the data into your new Amazon S3 data lake.\\n\\n• Lake Formation organizes data in S3 around frequently used query terms and into right-sized chunks to increase efficiency.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 2}), Document(page_content='• Lake Formation changes data into formats like Apache Parquet and ORC for faster analytics.\\n\\n• Lake Formation has built-in machine learning to deduplicate and find matching records (two entries that refer to the same thing) to increase data quality.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 2}), Document(page_content='Simplify security management • Lake Formation provides its own permissions model that augments the AWS Identity and Access Management (IAM) permissions and enables fine-grained access to data stored in data lakes through a simple grant/revoke mechanism.\\n\\n• Lake Formation permissions are enforced at the table and column level across the full portfolio of AWS analytics and machine learning services.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 2}), Document(page_content='• Lake Formation is used to centrally define security, governance, and auditing policies in one place, versus doing these tasks per service.\\n\\n• Your policies are consistently implemented, eliminating the need to manually configure them across services like AWS IAM, AWS KMS, Amazon S3, Redshift, Athena, and (in beta) EMR for Apache Spark.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 2}), Document(page_content='Provide self-service access to data • By providing a catalog of your data with consistent security enforcement, Lake Formation makes it easier for your analysts and data scientists to use their preferred analytics service.\\n\\n• Your users can use diverse data sets now housed in a single data lake.\\n\\nThey can also combine these services without having to move data between silos.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 2}), Document(page_content='1 How Lake Formation works  The following diagram illustrates how data is loaded and secured in Lake Formation.\\n\\nAWS Lake Formation makes it easier for you to build, secure, and manage data lakes.\\n\\nLake Formation helps you do the following, either directly or through other AWS services: 1.\\n\\nRegister the Amazon Simple Storage Service (Amazon S3) buckets and paths where your data lake will reside.\\n\\n2.\\n\\nOrchestrate data flows that ingest, cleanse, transform, and organize raw data.\\n\\n3.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 3}), Document(page_content='3.\\n\\nCreate and manage a Data Catalog containing metadata about data sources and data in the data lake.\\n\\n4.\\n\\nDefine granular data access policies to the resources • metadata  • underlying data   As the diagram shows, Lake Formation manages AWS Glue crawlers, AWS Glue ETL jobs, the Data Catalog, security settings, and access control.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 3}), Document(page_content='After the data is securely stored in the data lake, users can access the data through their choice of analytics services, including Amazon Athena, Amazon Redshift, and Amazon EMR.\\n\\nAWS Lake Formation is built on AWS Glue and interacts in the following ways: • Lake Formation and AWS Glue share the same Data Catalog.\\n\\n• AWS Glue To orchestrate jobs and crawlers to transform data • The workflows generated with LF blueprint are AWS Glue workflows.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 3}), Document(page_content='• ML transforms are provided with LF and are built on AWS Glue API operations.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 3}), Document(page_content='1 Security and Access Control to Metadata and Data in Lake Formation  Lake Formation uses a combination of Lake Formation and IAM permissions.\\n\\n1.\\n\\nLake Formation permissions control access to Data Catalog resources: • Metadata (AWS Data Catalog) • Underlying data at S3 locations 2.\\n\\nIAM permissions control access to the ALF and AWS Glue APIs and resources.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 4}), Document(page_content='AWS Lake Formation Fine-grained Access   IAM Permissions Lake Formation Permissions Coarse-grained:  Broader permissions on individual operations and on access to Amazon S3 locations.\\n\\nFor example, include \"glue:*\" or \"glue:Create*\" rather than \"glue:CreateTables\", leaving Lake Formation permissions to control whether or not a principal can create catalog objects.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 4}), Document(page_content='Fine-grained:  Granting limited Lake Formation permissions to individual principals on individual Data Catalog resources, Amazon S3 locations, and the underlying data in those locations.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 4}), Document(page_content='1 Access control in AWS Lake Formation is divided into the following two areas:  1.\\n\\nMetadata access control (Data Catalog permissions) • To create, read, update, and delete metadata databases, tables in Data Catalog.\\n\\n2.\\n\\nUnderlying data access control • Data access permissions to read and write data to underlying Amazon S3 locations.\\n\\n• Data location permissions to create metadata databases and tables that point to specific Amazon S3 locations.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 5}), Document(page_content='Access control in AWS Lake Formation  Data Catalog permissions Data access permissions Data location permissions Catalog Database Table Table S3 Location CREATE_DATABASE CREATE_TABLE ALTER DROP DESCRIBE ALTER DROP DESCRIBE  SELECT INSERT DELETE DATA_LOCATION_ACCESS', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 5}), Document(page_content='1 Metadata access control   Metadata access control   Lake Formation Permissions Resource  Required additional IAM permission  Granted Access CREATE_DATABASE  Need data location permissions if the  location property is specified, and the location is managed by Lake Formation.\\n\\nData Catalog glue:CreateDatabase Create a metadata database or resource link in the Data Catalog.\\n\\nCREATE_TABLE in the database, ALTER database, DROP database.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 6}), Document(page_content='CREATE_TABLE  All Lake Formation permissions on the table are granted to the principal who creates a table.\\n\\nDatabase glue:CreateTable Create a metadata table or resource link in the Data Catalog within the specified database.\\n\\nALTER  Need data location permissions if the property being altered is a registered Amazon S3 location.\\n\\nDatabase glue:UpdateDatabase Alter metadata of  a database.\\n\\nTable glue:UpdateTable Alter metadata of  a table.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 6}), Document(page_content='Table glue:UpdateTable Alter metadata of  a table.\\n\\nDROP  Cannot be granted  on a database to an external account or organization.\\n\\nDropping a database drops all tables in the database.\\n\\nDatabase glue:DeleteDatabase Drop a database in Data Catalog.\\n\\nTable glue:DeleteTable Drop a table in Data Catalog.\\n\\nResource link glue:DeleteDatabase glue:DeleteTable Drop a resource link  in Data Catalog.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 6}), Document(page_content='DESCRIBE  Implicitly granted if a user has other Lake Formation permissions on a database, table, or resource link.\\n\\nDatabase glue:GetDatabase  View metadata of a database.\\n\\nTable glue:GetTable  View metadata of a table.\\n\\nResource link glue:GetTable   glue:GetDatabase  View metadata of a resource link', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 6}), Document(page_content='1 Underlying data access control  To enable Lake Formation principals to read and write underlying data with access controlled by Lake Formation permissions:  1.\\n\\nThe Amazon S3 locations that contain the data must be registered with Lake Formation.\\n\\n2.\\n\\nPrincipals who create Data Catalog tables that point to underlying data locations must have data location permissions.\\n\\n3.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 7}), Document(page_content='3.\\n\\nPrincipals who read and write underlying data must have Lake Formation data access permissions on the Data Catalog tables that point to the underlying data locations.\\n\\nThey must also have lakeformation:GetDataAccess IAM permission.\\n\\n• Amazon Athena requires the user to have this permission.\\n\\n• Assumed role for other integrated services must have this permission.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 7}), Document(page_content='When an integrated AWS service requests access to data in an Amazon S3 location that is access-controlled by AWS Lake Formation, Lake Formation supplies temporary credentials to access the data.\\n\\nUnderlying data access control  Lake Formation Permissions Resource  Required additional IAM permission  Granted Access INSERT   TABLE lakeformation: GetDataAccess Insert, update, and read underlying data at the Amazon S3 location specified by the table.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 7}), Document(page_content=\"SELECT  When granting SELECT, you can't include the grant option if column filtering is applied.\\n\\nYou cannot restrict access control on columns that are partition keys.\\n\\nTABLE lakeformation: GetDataAccess Read the underlying data in Amazon S3 at the location specified by the table.\", metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 7}), Document(page_content='If column filtering was applied when this permission was granted, the principal can view the metadata only for the included columns and can query data only from the included columns DELETE   TABLE lakeformation: GetDataAccess Delete underlying data at the Amazon S3 location specified by the table.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 7}), Document(page_content='1 Data Location Permissions Data location permissions in AWS Lake Formation enable principals to create and alter Data Catalog metadata that point to designated registered Amazon S3 locations.\\n\\nData location permissions provide an extra layer of security to locations within the data lake.\\n\\nWhen you grant the CREATE_TABLE or ALTER permission to a principal, you also grant data location permissions to limit the locations for which the principal can create or alter metadata tables.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 8}), Document(page_content='Data location permissions govern the outcome of create and update operations on Data Catalog databases and tables.\\n\\nThe rules are as follows:  • A principal must have explicit or implicit data location permissions on an Amazon S3 location to create or update a database or table that specifies that location.\\n\\n• The explicit permission DATA_LOCATION_ACCESS can be granted using the console, API, or AWS CLI.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 8}), Document(page_content='• If a principal is granted data location permissions on a location, the principal has data location permissions on all child locations.\\n\\n• Data location permissions apply only to creating or altering Data Catalog databases and tables that point to the location.\\n\\n• A principal does not need data location permissions to perform read/write operations on the underlying data on existing tables..\\n\\nIt is sufficient to have the SELECT or INSERT data access permissions.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 8}), Document(page_content='1 Cross-Account Access  Large enterprises typically use multiple AWS accounts, and many of those accounts might need access to a data lake managed by a single AWS account.\\n\\nAWS Lake Formation allows cross-account access to Data Catalog metadata and underlying data.\\n\\nUsers and AWS Glue ETL jobs can query and join tables across multiple accounts and still take advantage of Lake Formation table-level and column-level data protections.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 9}), Document(page_content=\"You don't share resources with specific principals in external AWS accounts—you share the resources only with the accounts.\\n\\nGranting Lake Formation permissions to an organization or organizational unit is equivalent to granting the permission to every AWS account in that organization or organizational unit.\", metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 9}), Document(page_content='AWS Resource Access Manager  When you grant Lake Formation permissions on a Data Catalog resource to an external account, Lake Formation uses the AWS Resource Access Manager (AWS RAM) service to share the resource.\\n\\n• If the grantee account is in the same organization as the grantor account, the shared resource is available immediately to the grantee.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 9}), Document(page_content='• If the grantee account is not in the same organization, AWS RAM sends an invitation to the grantee account to accept or reject the resource grant.\\n\\nThen, to make the shared resource available, the data lake administrator in the grantee account must use the AWS RAM console or CLI to accept the invitation.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 9}), Document(page_content='1 Lake Formation Personas and IAM Permissions  The following tables lists the suggested AWS Lake Formation personas and their permissions.\\n\\nAWS Lake Formation Personas Persona  Description IAM administrator (superuser) (Required) User who can create IAM users and roles.\\n\\nHas the AdministratorAccess AWS managed policy.\\n\\nHas all permissions on all Lake Formation resources.\\n\\nCan add data lake administrators.\\n\\nCannot grant Lake Formation permissions if not also designated a data lake administrator.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 10}), Document(page_content='Data lake administrator (Required) User who can register Amazon S3 locations, access the Data Catalog, create databases, create and run workflows, grant Lake Formation permissions to other users, and view AWS CloudTrail logs.\\n\\nHas fewer IAM permissions than the IAM administrator, but enough to administer the data lake.\\n\\nCannot add other data lake administrators.\\n\\nWorkflow role (Required) Role that runs a workflow on behalf of a user.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 10}), Document(page_content='You specify this role when you create a workflow from a blueprint.\\n\\nData engineer User who can create and run crawlers and workflows and grant Lake Formation permissions on the Data Catalog tables that the crawlers and workflows create.\\n\\nData analyst User who can run queries against the data lake using, for example, Amazon Athena.\\n\\nHas only enough permissions to run queries.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 10}), Document(page_content='Has only enough permissions to run queries.\\n\\nAWS Managed Policy Comments AWSGlueConsoleFullAccess Allows the principal to conduct a variety of operations on the Lake Formation console.\\n\\nAWSLakeFormationDataAdmin Allows the data lake administrator to conduct administrative operations and view AWS CloudTrail logs.\\n\\nAWSLakeFormationCrossAccountManager Allows the principal to grant Lake Formation permissions to external AWS accounts, to organizations, or to organizational units.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 10}), Document(page_content='The AWSLakeFormationDataAdmin policy does not grant every required permission for data lake administrators.\\n\\nAdditional permissions are needed to create and run workflows and register locations with the service linked role AWSServiceRoleForLakeFormationDataAccess.\\n\\nFor more information, see Create a Data Lake Administrator and Using Service-Linked Roles for Lake Formation.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 10}), Document(page_content='In addition, AWS Glue and Lake Formation assume the service role AWSGlueServiceRole to allow access to related services, including Amazon Elastic Compute Cloud (Amazon EC2), Amazon Simple Storage Service (Amazon S3), and Amazon CloudWatch.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 10}), Document(page_content='1 AWS Lake Formation Controls and Architecture   The following topics answers common security concerns to the corresponding controls and architectural best practices as documented in AWS public documentation, white papers, and blog posts.\\n\\nAWS Lake Formation Controls and Architecture  Network Isolation  • Lake Formation supports private endpoints in your VPC and records all activity in AWS CloudTrail, so you have network isolation and auditability.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 11}), Document(page_content='• AWS Lake Formation provides API operations through several language-specific SDKs and the AWS Command Line Interface (AWS CLI).\\n\\n• The Lake Formation API focuses primarily on managing Lake Formation permissions, while the AWS Glue API provides a data catalog API and a managed infrastructure for defining, scheduling, and running ETL operations on your data.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 11}), Document(page_content='• If your organization uses transit gateway to scale your network or private link , ALF/ AWS Glue does support through VPC Isolation of physical hosts, update/patch/ harden the hosts AWS Lake Formation is serverless managed service.\\n\\nThere is no infrastructure to provision or manage.\\n\\nIntegration with IAM  • Lake Formation integrates with IAM so authenticated users and roles can be automatically mapped to data protection policies that are stored in the Data Catalog.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 11}), Document(page_content='• The IAM integration also enables you to use Microsoft Active Directory or LDAP to federate into IAM using SAML.\\n\\nCompliance programs  AWS Glue and AWS Lake Formation are compliant with SOC 1, SOC 2, SOC 3, PCI, ISMAP and HIPAA.\\n\\nReference: https://aws.amazon.com/compliance/services-in-scope/ Encryption of data at-rest  • ALF currently supports Server-Side-Encryption on S3 (SSE-S3, AES-256) for encrypting your AWS Glue Data Catalog metadata and connection passwords.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 11}), Document(page_content='• AWS KMS key is automatically used when objects, such as tables, are written to the Data Catalog.\\n\\n• The encrypted objects include the Databases, Tables, Partitions, Table versions, Connections and User-defined functions.\\n\\nReference: Encrypting Your Data Catalog  Encryption in Transit  • AWS provides Secure Sockets Layer (SSL) encryption for data in motion.\\n\\nYou can configure encryption settings for crawlers, ETL jobs, and development endpoints using security configurations in AWS', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 11}), Document(page_content='1 Glue.\\n\\nYou can enable AWS Glue Data Catalog encryption via the settings for the Data Catalog.\\n\\n• As of September 4, 2018, AWS KMS (bring your own key and server-side encryption) for AWS Glue ETL and the AWS Glue Data Catalog is supported.\\n\\nEncryption Key Management  • AWS Lake Formation integrates with AWS KMS to enable you to more easily set up other integrated services to encrypt and decrypt data in Amazon Simple Storage Service (Amazon S3) locations.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 12}), Document(page_content='• Both customer master keys (CMKs) and AWS managed CMKs are supported.\\n\\n• Client- side encryption/decryption is not supported.\\n\\nAuthentication and authorization of corporate users • Beginning with Amazon EMR 5.31.0, Lake Formation supports  Federated single sign-on to EMR Notebooks or Apache Zeppelin from enterprise identity systems compatible with Security Assertion Markup Language (SAML) 2.0.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 12}), Document(page_content='• Lake Formation supports Athena users who connect through the JDBC or ODBC driver and authenticate through SAML.\\n\\nSupported SAML providers include Okta and Microsoft Active Directory Federation Service (AD FS).', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 12}), Document(page_content=\"Audit Logging AWS Glue API Calls with AWS CloudTrail  AWS Glue is integrated with AWS CloudTrail to determine  • The request that was made to AWS Glue • The IP address from which the request was made • Who made the request (Root or IAM user credentials, Temporary security credentials for a role or federated user by another AWS service.\\n\\nWhen a recipient AWS account accesses data in a shared table, Lake Formation copies the CloudTrail event to the owning account's CloudTrail logs.\", metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 12}), Document(page_content='Reference: Logging Using CloudTrail,  Cross-Account CloudTrail Logging Alerting for Audit events  You can be notified when CloudTrail publishes new log files to your Amazon S3 bucket by using Amazon Simple Notification Service (Amazon SNS).\\n\\nReference: Configuring Amazon SNS Notifications for CloudTrail Monitoring • You can profile and monitor AWS Glue operations using AWS Glue job profiler.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 12}), Document(page_content='It collects and processes raw data from AWS Glue jobs into readable, near real-time metrics stored in Amazon CloudWatch.\\n\\n• AWS Glue reports metrics to CloudWatch every 30 seconds, and the CloudWatch metrics dashboards are configured to display them every minute.\\n\\nReference: Using CloudWatch Metrics Alerts and Remediation You can use Amazon CloudWatch Events to automate your AWS services and respond automatically to system events such as application availability issues or resource changes.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 12}), Document(page_content='The actions that can be automatically triggered include:  • Activating a Lambda function when an ETL job succeeds • Notifying an Amazon SNS topic when an ETL job fails', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 12}), Document(page_content='1  Reference: Automating with CloudWatch Events Applications Development and Debugging • You can create development endpoint to iteratively develop and test ETL scripts.\\n\\n• You can then create a notebook that connects to the endpoint, and use your notebook to author and test your ETL script.\\n\\nLake Formation Service Access  Lake Formation console: To define and manage your data lake and grant and revoke Lake Formation permissions.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 13}), Document(page_content='Lake Formation API and CLI: The Lake Formation API focuses primarily on managing Lake Formation permissions, while the AWS Glue API provides a data catalog API and a managed infrastructure for defining, scheduling, and running ETL operations on your data.\\n\\nData Catalog: To store metadata about data lakes, data sources, transforms, and targets.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 13}), Document(page_content='Blueprint: A data management template that enables you to easily ingest data into a data lake for a predefined source type, such as a relational database or AWS CloudTrail logs.\\n\\nFrom a blueprint, you can create a workflow.\\n\\nWorkflow: It consists of AWS Glue crawlers, jobs, and triggers that are generated to orchestrate the loading and update of data.', metadata={'source': '../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf', 'page': 13})]\n",
      "AWS Service Approval Accelerator for AWS Lake Formation.pdf Loaded successfully\n",
      "The file is loaded and the vector library is being generated\n",
      "Embedding Error: Error raised by inference endpoint: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\n",
      "  \"code\": 400,\n",
      "  \"type\": \"InternalServerException\",\n",
      "  \"message\": \"The size of tensor a (775) must match the size of tensor b (512) at non-singleton dimension 1\"\n",
      "}\n",
      "\". See https://us-west-1.console.aws.amazon.com/cloudwatch/home?region=us-west-1#logEventViewer:group=/aws/sagemaker/Endpoints/huggingface-inference-eb-bge-en in account 513489159680 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish embedding, text len: 55 4288\n",
      "File import takes time: 0:00:08.769100\n",
      "Complete the import of the following documents: ['../docs/english_docs/AWS Service Approval Accelerator for AWS Lake Formation.pdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load the file: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None of the files loaded successfully, please check the file to upload again.\n",
      "File import takes time: 0:00:00.002884\n",
      "Complete the import of the following documents: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if language == \"english\":\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "\n",
    "search_qa = SmartSearchQA()\n",
    "search_qa.init_cfg(index,\n",
    "                 username,\n",
    "                 password,\n",
    "                 host,\n",
    "                 port,\n",
    "                 EMBEDDING_ENDPOINT_NAME,\n",
    "                 region,\n",
    "                 language=language\n",
    "                 )\n",
    "\n",
    "# local_path = \"../test_file/\"\n",
    "local_path = \"../docs/english_docs/\"\n",
    "\n",
    "files = os.listdir(local_path)\n",
    "for file in files:\n",
    "    local_file = local_path+file\n",
    "    now1 = datetime.now()#begin time\n",
    "    loaded_files = search_qa.init_knowledge_vector(local_file,bulk_size)\n",
    "    now2 = datetime.now()#endtime\n",
    "    print(\"File import takes time:\",now2-now1)\n",
    "    print(\"Complete the import of the following documents:\", str(loaded_files))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c648694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
